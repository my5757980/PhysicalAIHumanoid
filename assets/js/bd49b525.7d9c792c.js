"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[5091],{1937:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>h,frontMatter:()=>a,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"chapter-3/index","title":"Chapter 3: AI for Embodied Intelligence","description":"Overview","source":"@site/docs/chapter-3/index.md","sourceDirName":"chapter-3","slug":"/chapter-3/","permalink":"/PhysicalAIHumanoid/docs/chapter-3/","draft":false,"unlisted":false,"editUrl":"https://github.com/my5757980/PhysicalAIHumanoid/tree/main/docs/chapter-3/index.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"textbookSidebar","previous":{"title":"Mechatronic Integration","permalink":"/PhysicalAIHumanoid/docs/chapter-2/mechatronic-integration"},"next":{"title":"Computer Vision, SLAM, Perception Stacks","permalink":"/PhysicalAIHumanoid/docs/chapter-3/computer-vision-slam"}}');var o=i(4848),r=i(8453);const a={sidebar_position:1},s="Chapter 3: AI for Embodied Intelligence",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Table of Contents",id:"table-of-contents",level:2},{value:"Summary",id:"summary",level:2}];function d(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"chapter-3-ai-for-embodied-intelligence",children:"Chapter 3: AI for Embodied Intelligence"})}),"\n",(0,o.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,o.jsx)(n.p,{children:"This chapter explores the artificial intelligence techniques that enable embodied systems to perceive, learn, and make decisions in physical environments. We'll examine computer vision and perception systems that allow robots to understand their surroundings, reinforcement learning approaches for control and skill acquisition, imitation learning from human demonstrations, and planning algorithms for autonomous decision-making. These AI techniques, when integrated with physical systems, create the foundation for truly intelligent robots."}),"\n",(0,o.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsx)(n.p,{children:"By the end of this chapter, you should be able to:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Understand computer vision and SLAM techniques for robotic perception"}),"\n",(0,o.jsx)(n.li,{children:"Explain reinforcement learning approaches for robot control and skill acquisition"}),"\n",(0,o.jsx)(n.li,{children:"Analyze imitation learning and teleoperation methods for skill transfer"}),"\n",(0,o.jsx)(n.li,{children:"Evaluate decision-making and planning algorithms for robotic tasks"}),"\n",(0,o.jsx)(n.li,{children:"Assess the role of multimodal models in embodied intelligence"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"table-of-contents",children:"Table of Contents"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.a,{href:"/PhysicalAIHumanoid/docs/chapter-3/computer-vision-slam",children:"Computer Vision, SLAM, Perception Stacks"})," - Object detection, SLAM, sensor fusion"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.a,{href:"/PhysicalAIHumanoid/docs/chapter-3/reinforcement-learning-control",children:"Reinforcement Learning for Control"})," - Model-free & model-based RL, deep RL algorithms"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.a,{href:"/PhysicalAIHumanoid/docs/chapter-3/imitation-learning-teleoperation",children:"Imitation Learning & Teleoperation"})," - Behavioral cloning, inverse RL, teleoperation systems"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.a,{href:"/PhysicalAIHumanoid/docs/chapter-3/decision-making-planning",children:"Decision Making & Planning"})," - Classical planning, motion planning, POMDP, task reasoning"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.a,{href:"/PhysicalAIHumanoid/docs/chapter-3/multimodal-models",children:"Multimodal Models for Robots"})," - Vision, audio, tactile, proprioception integration"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(n.p,{children:"This chapter examined the AI techniques that enable embodied systems to perceive, learn, and make decisions. We explored computer vision and SLAM systems that allow robots to understand their environment, reinforcement learning approaches for control and skill acquisition, imitation learning from human demonstrations, and planning algorithms for autonomous decision-making. The integration of multimodal models was highlighted as a key approach for creating more robust and comprehensive understanding. These AI techniques, when combined with physical systems, create the foundation for truly intelligent robotic behavior."})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>s});var t=i(6540);const o={},r=t.createContext(o);function a(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);